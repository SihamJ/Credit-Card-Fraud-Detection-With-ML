{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing\n",
    "import numpy as np # working with arrays\n",
    "import matplotlib.pyplot as plt # visualization\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,History\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report,precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_url):\n",
    "    print(\"Loading data ...\",end=\" \")\n",
    "    df = pd.read_excel(data_url)\n",
    "    #df.drop(['V7_day','V6_day'], axis=1, inplace=True)\n",
    "    X = df.drop(\"CLASS\", axis=1)\n",
    "    y = df[\"CLASS\"]\n",
    "    X = X.values\n",
    "    y = y.values\n",
    "    print('\\033[32m \\u2713 \\033[0m')\n",
    "    return X,y\n",
    "\n",
    "def split_data(X,y):\n",
    "    print(\"Split data ...\",end=\" \")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print('\\033[32m \\u2713 \\033[0m')\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def save_model(model,name):\n",
    "    print(\"Saving \"+name+\" model ...\",end=\" \")\n",
    "    pickle.dump(model, open(\"./models/\"+name+\".pkl\",\"wb\"))\n",
    "    print('\\033[32m \\u2713 \\033[0m')\n",
    "\n",
    "def print_metrics(y_test,y_pred): \n",
    "    \"\"\"n_errors = (y_pred != y_test).sum()\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"The accuracy is {}\".format(acc))\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    print(\"The precision is {}\".format(prec))\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    print(\"The recall is {}\".format(rec))\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(\"The F1-Score is {}\".format(f1))\"\"\"\n",
    "    print(\"\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "\n",
    "def confusion_matr(y_test,y_pred):\n",
    "    # printing the confusion matrix\n",
    "    LABELS = ['Normal', 'Fraud']\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize =(8, 4))\n",
    "    sns.heatmap(conf_matrix, xticklabels = LABELS,yticklabels = LABELS, annot = True, fmt =\"d\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel('True class')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.show()\n",
    "\n",
    "def d_tree(X_train, X_test, y_train, y_test):\n",
    "    print(\"Creating DT model ...\",end=\" \")\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    print('\\033[32m \\u2713 \\033[0m')\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print_metrics(y_test,y_pred)\n",
    "    return clf\n",
    "\n",
    "def r_forest(X_train, X_test, y_train, y_test):\n",
    "    print(\"Creating RF model ...\",end=\" \")\n",
    "    rfc = RandomForestClassifier()\n",
    "    rfc.fit(X_train, y_train)\n",
    "    print('\\033[32m \\u2713 \\033[0m')\n",
    "\n",
    "    y_pred = rfc.predict(X_test)\n",
    "    print_metrics(y_test,y_pred)\n",
    "    #print(classification_report(y_test,y_pred))\n",
    "    #confusion_matr(y_test,y_pred)\n",
    "    \n",
    "    return rfc\n",
    "\n",
    "def ex_tree(X_train, X_test, y_train, y_test):\n",
    "    print(\"Creating Extra_T model ...\",end=\" \")\n",
    "    etc = ExtraTreesClassifier(n_estimators=100, max_depth=4)\n",
    "    etc.fit(X_train, y_train)\n",
    "    print('\\033[32m \\u2713 \\033[0m')\n",
    "    y_pred = etc.predict(X_test)\n",
    "    print_metrics(y_test,y_pred)\n",
    "    #confusion_matr(y_test,y_pred)\n",
    "    return etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ... \u001b[32m ✓ \u001b[0m\n",
      "Split data ... \u001b[32m ✓ \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((79999, 36), (20000, 36))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url='C:/Users/KABYADE/Desktop/Fraud_ML/dataset/preprocessing_data.xlsx'\n",
    "X,y=load_data(data_url)\n",
    "X_train, X_test, y_train, y_test=split_data(X,y)\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99999"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url='C:/Users/KABYADE/Desktop/Fraud_ML/dataset/preprocessing_data.xlsx'\n",
    "df = pd.read_excel(r'C:\\Users\\KABYADE\\Desktop\\Fraud_ML\\dataset\\preprocessing_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Extra_T model ... \u001b[32m ✓ \u001b[0m\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.50      0.48       303\n",
      "           2       1.00      0.66      0.79       322\n",
      "           3       1.00      1.00      1.00       332\n",
      "           4       0.36      0.41      0.38       326\n",
      "           5       0.94      0.45      0.61       322\n",
      "           6       0.25      0.06      0.09       320\n",
      "           7       0.75      0.01      0.02       325\n",
      "           8       0.68      0.81      0.74       339\n",
      "           9       1.00      0.78      0.88       327\n",
      "          10       1.00      1.00      1.00       312\n",
      "          11       1.00      0.46      0.63       364\n",
      "          12       0.36      0.41      0.38       313\n",
      "          13       0.34      0.12      0.17       313\n",
      "          14       0.35      1.00      0.52       338\n",
      "          15       0.82      1.00      0.90       296\n",
      "          16       0.13      0.03      0.05       307\n",
      "          17       0.14      0.69      0.23       306\n",
      "          18       0.72      1.00      0.84       333\n",
      "          19       0.74      0.34      0.47       327\n",
      "          20       1.00      0.89      0.94       308\n",
      "          21       0.50      0.99      0.67       322\n",
      "          22       0.39      0.58      0.47       297\n",
      "          23       1.00      1.00      1.00       317\n",
      "          24       0.28      0.52      0.37       319\n",
      "          25       0.00      0.00      0.00       312\n",
      "          26       0.72      1.00      0.84       317\n",
      "          27       0.64      1.00      0.78       311\n",
      "          28       0.75      0.26      0.39       321\n",
      "          29       0.30      0.40      0.34       302\n",
      "          30       0.50      0.77      0.60       294\n",
      "          31       0.00      0.00      0.00       309\n",
      "          32       0.00      0.00      0.00       324\n",
      "          33       0.00      0.00      0.00       346\n",
      "          34       0.00      0.00      0.00       323\n",
      "          35       0.78      0.19      0.31       336\n",
      "          36       0.10      0.39      0.16       298\n",
      "          37       0.11      0.16      0.13       298\n",
      "          38       0.30      0.61      0.40       307\n",
      "          39       0.94      1.00      0.97       301\n",
      "          40       0.95      0.98      0.96       318\n",
      "          41       0.20      0.01      0.02       312\n",
      "          42       0.33      0.01      0.02       314\n",
      "          43       0.00      0.00      0.00       321\n",
      "          44       0.88      0.50      0.64       291\n",
      "          45       0.99      0.82      0.90       295\n",
      "          46       0.86      1.00      0.93       326\n",
      "          47       0.34      0.54      0.42       311\n",
      "          48       0.00      0.00      0.00       332\n",
      "          49       0.65      0.88      0.74       325\n",
      "          50       0.00      0.00      0.00       324\n",
      "          51       0.49      0.21      0.30       289\n",
      "          52       0.97      0.10      0.19       349\n",
      "          53       0.81      1.00      0.90       336\n",
      "          54       0.99      1.00      0.99       311\n",
      "          55       0.68      0.84      0.75       332\n",
      "          56       1.00      1.00      1.00       304\n",
      "          57       0.00      0.00      0.00       316\n",
      "          58       0.99      1.00      0.99       317\n",
      "          59       1.00      1.00      1.00       316\n",
      "          60       0.96      1.00      0.98       293\n",
      "          61       0.19      0.36      0.25       330\n",
      "          62       0.17      0.38      0.24       323\n",
      "          63       0.31      0.59      0.40       328\n",
      "\n",
      "    accuracy                           0.53     20000\n",
      "   macro avg       0.54      0.53      0.49     20000\n",
      "weighted avg       0.54      0.53      0.49     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KABYADE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\KABYADE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\KABYADE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "ext=ex_tree(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DT model ... \u001b[32m ✓ \u001b[0m\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       303\n",
      "           2       1.00      1.00      1.00       322\n",
      "           3       1.00      1.00      1.00       332\n",
      "           4       0.34      0.35      0.35       326\n",
      "           5       0.99      1.00      1.00       322\n",
      "           6       0.34      0.36      0.35       320\n",
      "           7       0.53      0.52      0.52       325\n",
      "           8       1.00      1.00      1.00       339\n",
      "           9       1.00      1.00      1.00       327\n",
      "          10       1.00      1.00      1.00       312\n",
      "          11       0.59      0.59      0.59       364\n",
      "          12       0.78      0.78      0.78       313\n",
      "          13       0.30      0.27      0.29       313\n",
      "          14       1.00      1.00      1.00       338\n",
      "          15       1.00      1.00      1.00       296\n",
      "          16       0.52      0.54      0.53       307\n",
      "          17       1.00      1.00      1.00       306\n",
      "          18       1.00      1.00      1.00       333\n",
      "          19       0.59      0.64      0.61       327\n",
      "          20       0.99      0.99      0.99       308\n",
      "          21       0.99      1.00      0.99       322\n",
      "          22       1.00      0.99      0.99       297\n",
      "          23       1.00      1.00      1.00       317\n",
      "          24       0.37      0.36      0.37       319\n",
      "          25       0.42      0.42      0.42       312\n",
      "          26       0.99      1.00      1.00       317\n",
      "          27       0.99      0.99      0.99       311\n",
      "          28       1.00      0.99      1.00       321\n",
      "          29       0.31      0.29      0.30       302\n",
      "          30       0.99      0.99      0.99       294\n",
      "          31       0.58      0.60      0.59       309\n",
      "          32       0.55      0.57      0.56       324\n",
      "          33       0.35      0.31      0.32       346\n",
      "          34       0.59      0.59      0.59       323\n",
      "          35       0.92      0.88      0.90       336\n",
      "          36       0.13      0.14      0.14       298\n",
      "          37       0.18      0.19      0.19       298\n",
      "          38       1.00      1.00      1.00       307\n",
      "          39       1.00      1.00      1.00       301\n",
      "          40       1.00      1.00      1.00       318\n",
      "          41       0.15      0.16      0.16       312\n",
      "          42       0.20      0.19      0.19       314\n",
      "          43       1.00      1.00      1.00       321\n",
      "          44       1.00      1.00      1.00       291\n",
      "          45       1.00      1.00      1.00       295\n",
      "          46       1.00      1.00      1.00       326\n",
      "          47       0.55      0.59      0.57       311\n",
      "          48       0.47      0.47      0.47       332\n",
      "          49       1.00      1.00      1.00       325\n",
      "          50       0.46      0.47      0.46       324\n",
      "          51       1.00      0.99      0.99       289\n",
      "          52       0.99      1.00      0.99       349\n",
      "          53       1.00      1.00      1.00       336\n",
      "          54       1.00      1.00      1.00       311\n",
      "          55       1.00      1.00      1.00       332\n",
      "          56       1.00      1.00      1.00       304\n",
      "          57       0.84      0.83      0.83       316\n",
      "          58       1.00      1.00      1.00       317\n",
      "          59       1.00      1.00      1.00       316\n",
      "          60       1.00      1.00      1.00       293\n",
      "          61       0.37      0.38      0.38       330\n",
      "          62       0.35      0.34      0.35       323\n",
      "          63       0.51      0.48      0.50       328\n",
      "\n",
      "    accuracy                           0.76     20000\n",
      "   macro avg       0.77      0.77      0.77     20000\n",
      "weighted avg       0.76      0.76      0.76     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision_Tree\n",
    "dt=d_tree(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd=r_forest(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(ext,\"Ex_Trees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=[  4,  2,  23,  1,  410878,  715848.0,  19,  2976,  44,  20339,  3,  1,  621524,  1,  \n",
    "             384,  4,  0.654861,  0.654861, -1.0, -0.5,  0.959493, -0.978148,  2009,  2011,  2009,  2009 \n",
    "           ]\n",
    "to_predict = np.array(test_data).reshape(1,26)\n",
    "\n",
    "rf_model = pickle.load(open(\"models/R_forest.pkl\",\"rb\"))\n",
    "rf_model.predict(to_predict) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38db7db662a93b92d35804601f8e71aa4f29fb454ddd5b4d70af8eaaf7f2bce7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
