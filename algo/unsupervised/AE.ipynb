{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 15:36:38.214834: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-09 15:36:38.723849: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-09 15:36:38.723883: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-09 15:36:39.966913: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-09 15:36:39.967004: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-09 15:36:39.967010: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import preprocessing \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "np.random.seed(203)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/home/sihartist/Desktop/\"\n",
    "path = root + \"fraud-detection/dataset/preprocessing_data.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V16</th>\n",
       "      <th>V19</th>\n",
       "      <th>...</th>\n",
       "      <th>SIN(V7_day)</th>\n",
       "      <th>SIN(V23_month)</th>\n",
       "      <th>SIN(V23_day)</th>\n",
       "      <th>SIN(V8_month)</th>\n",
       "      <th>SIN(V8_day)</th>\n",
       "      <th>V6_year</th>\n",
       "      <th>V7_year</th>\n",
       "      <th>V23_year</th>\n",
       "      <th>V8_year</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>517511</td>\n",
       "      <td>478657.0</td>\n",
       "      <td>19</td>\n",
       "      <td>2976</td>\n",
       "      <td>44</td>\n",
       "      <td>20342</td>\n",
       "      <td>...</td>\n",
       "      <td>7.657137e-16</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.937752</td>\n",
       "      <td>0.174152</td>\n",
       "      <td>-0.201299</td>\n",
       "      <td>2009</td>\n",
       "      <td>2011</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>656609</td>\n",
       "      <td>57651.0</td>\n",
       "      <td>19</td>\n",
       "      <td>2976</td>\n",
       "      <td>44</td>\n",
       "      <td>1351</td>\n",
       "      <td>...</td>\n",
       "      <td>7.657137e-16</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.937752</td>\n",
       "      <td>-0.368810</td>\n",
       "      <td>0.937752</td>\n",
       "      <td>2009</td>\n",
       "      <td>2011</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>315952</td>\n",
       "      <td>166815.0</td>\n",
       "      <td>19</td>\n",
       "      <td>2976</td>\n",
       "      <td>44</td>\n",
       "      <td>25375</td>\n",
       "      <td>...</td>\n",
       "      <td>7.657137e-16</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.937752</td>\n",
       "      <td>0.174152</td>\n",
       "      <td>-0.394356</td>\n",
       "      <td>2008</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>475166</td>\n",
       "      <td>604595.0</td>\n",
       "      <td>19</td>\n",
       "      <td>2976</td>\n",
       "      <td>44</td>\n",
       "      <td>24577</td>\n",
       "      <td>...</td>\n",
       "      <td>7.657137e-16</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.937752</td>\n",
       "      <td>0.174152</td>\n",
       "      <td>-0.571268</td>\n",
       "      <td>2009</td>\n",
       "      <td>2011</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>61685</td>\n",
       "      <td>665491.0</td>\n",
       "      <td>19</td>\n",
       "      <td>2976</td>\n",
       "      <td>44</td>\n",
       "      <td>17010</td>\n",
       "      <td>...</td>\n",
       "      <td>7.657137e-16</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.937752</td>\n",
       "      <td>0.174152</td>\n",
       "      <td>-0.571268</td>\n",
       "      <td>2008</td>\n",
       "      <td>2010</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1  V2  V3  V4      V9       V10  V12   V13  V16    V19  ...   SIN(V7_day)  \\\n",
       "0   4   2  23   1  517511  478657.0   19  2976   44  20342  ...  7.657137e-16   \n",
       "1   4   2  23   1  656609   57651.0   19  2976   44   1351  ...  7.657137e-16   \n",
       "2   4   2  23   1  315952  166815.0   19  2976   44  25375  ...  7.657137e-16   \n",
       "3   4   2  23   1  475166  604595.0   19  2976   44  24577  ...  7.657137e-16   \n",
       "4   4   2  23   1   61685  665491.0   19  2976   44  17010  ...  7.657137e-16   \n",
       "\n",
       "   SIN(V23_month)  SIN(V23_day)  SIN(V8_month)  SIN(V8_day)  V6_year  V7_year  \\\n",
       "0        0.201299      0.937752       0.174152    -0.201299     2009     2011   \n",
       "1        0.201299      0.937752      -0.368810     0.937752     2009     2011   \n",
       "2        0.201299      0.937752       0.174152    -0.394356     2008     2009   \n",
       "3        0.201299      0.937752       0.174152    -0.571268     2009     2011   \n",
       "4        0.201299      0.937752       0.174152    -0.571268     2008     2010   \n",
       "\n",
       "   V23_year  V8_year  CLASS  \n",
       "0      2009     2009      0  \n",
       "1      2009     2009      0  \n",
       "2      2009     2009      0  \n",
       "3      2009     2009      0  \n",
       "4      2009     2009      0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop([\"CLASS\"], axis=1)\n",
    "y = data[\"CLASS\"].values\n",
    "x_scale = preprocessing.MinMaxScaler().fit_transform(x.values)\n",
    "x_norm, x_fraud = x_scale[y == 0], x_scale[y == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70327"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input layer \n",
    "input_layer = Input(shape=(x.shape[1],))\n",
    "\n",
    "## encoding part\n",
    "encoded = Dense(100, activation='tanh', activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoded = Dense(50, activation='relu')(encoded)\n",
    "\n",
    "## decoding part\n",
    "decoded = Dense(50, activation='tanh')(encoded)\n",
    "decoded = Dense(100, activation='tanh')(decoded)\n",
    "\n",
    "## output layer\n",
    "output_layer = Dense(x.shape[1], activation='relu')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_layer, output_layer)\n",
    "autoencoder.compile(optimizer=\"adadelta\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.2075 - val_loss: 0.2283\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.2038 - val_loss: 0.2238\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1993 - val_loss: 0.2181\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1935 - val_loss: 0.2106\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1858 - val_loss: 0.2009\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1761 - val_loss: 0.1904\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1662 - val_loss: 0.1811\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1577 - val_loss: 0.1734\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1506 - val_loss: 0.1671\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1449 - val_loss: 0.1620\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1404 - val_loss: 0.1578\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1368 - val_loss: 0.1543\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1339 - val_loss: 0.1515\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1316 - val_loss: 0.1493\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1299 - val_loss: 0.1475\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1284 - val_loss: 0.1459\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1272 - val_loss: 0.1446\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1260 - val_loss: 0.1433\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1247 - val_loss: 0.1419\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1233 - val_loss: 0.1404\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1219 - val_loss: 0.1389\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1206 - val_loss: 0.1374\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1193 - val_loss: 0.1360\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1182 - val_loss: 0.1346\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1171 - val_loss: 0.1333\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1161 - val_loss: 0.1320\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1151 - val_loss: 0.1308\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1142 - val_loss: 0.1296\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1134 - val_loss: 0.1286\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1127 - val_loss: 0.1276\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1120 - val_loss: 0.1264\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1106 - val_loss: 0.1239\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1077 - val_loss: 0.1205\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1049 - val_loss: 0.1180\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1029 - val_loss: 0.1161\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1013 - val_loss: 0.1147\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1002 - val_loss: 0.1136\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0994 - val_loss: 0.1127\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0987 - val_loss: 0.1120\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0981 - val_loss: 0.1114\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0977 - val_loss: 0.1110\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0973 - val_loss: 0.1106\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0970 - val_loss: 0.1102\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0967 - val_loss: 0.1099\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0965 - val_loss: 0.1096\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0963 - val_loss: 0.1093\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0960 - val_loss: 0.1091\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0958 - val_loss: 0.1089\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0956 - val_loss: 0.1086\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0954 - val_loss: 0.1084\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0953 - val_loss: 0.1082\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0951 - val_loss: 0.1080\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0949 - val_loss: 0.1078\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0947 - val_loss: 0.1076\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0946 - val_loss: 0.1074\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0944 - val_loss: 0.1072\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0942 - val_loss: 0.1070\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0941 - val_loss: 0.1068\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0939 - val_loss: 0.1066\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0938 - val_loss: 0.1064\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0936 - val_loss: 0.1062\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0934 - val_loss: 0.1060\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0933 - val_loss: 0.1058\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0931 - val_loss: 0.1056\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0929 - val_loss: 0.1054\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.1052\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0926 - val_loss: 0.1050\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0924 - val_loss: 0.1047\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0923 - val_loss: 0.1045\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0921 - val_loss: 0.1042\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0919 - val_loss: 0.1038\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0916 - val_loss: 0.1035\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0914 - val_loss: 0.1031\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0911 - val_loss: 0.1026\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0909 - val_loss: 0.1020\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0905 - val_loss: 0.1013\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0901 - val_loss: 0.1005\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0896 - val_loss: 0.0993\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0889 - val_loss: 0.0979\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0881 - val_loss: 0.0965\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0873 - val_loss: 0.0952\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0865 - val_loss: 0.0940\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0857 - val_loss: 0.0929\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0850 - val_loss: 0.0920\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0844 - val_loss: 0.0913\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0840 - val_loss: 0.0907\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0836 - val_loss: 0.0903\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0833 - val_loss: 0.0899\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0831 - val_loss: 0.0896\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0828 - val_loss: 0.0893\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0826 - val_loss: 0.0891\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0825 - val_loss: 0.0888\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0823 - val_loss: 0.0886\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0822 - val_loss: 0.0884\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0820 - val_loss: 0.0882\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0819 - val_loss: 0.0881\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0817 - val_loss: 0.0879\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0816 - val_loss: 0.0877\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0815 - val_loss: 0.0876\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0814 - val_loss: 0.0874\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(x_norm[0:60000], x_norm[0:60000], \n",
    "                batch_size = 256, epochs = 100, \n",
    "                shuffle = True, validation_split =0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "hid_rep = Sequential()\n",
    "hid_rep.add(autoencoder.layers[0])\n",
    "hid_rep.add(autoencoder.layers[1])\n",
    "hid_rep.add(autoencoder.layers[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 749us/step\n",
      "2198/2198 [==============================] - 2s 860us/step\n"
     ]
    }
   ],
   "source": [
    "norm_hid_rep = hid_rep .predict(x_norm[60000:])\n",
    "fraud_hid_rep = hid_rep .predict(x_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_84837/1249485764.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = non_fraud.append(fraud).sample(frac=1).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V16</th>\n",
       "      <th>V19</th>\n",
       "      <th>...</th>\n",
       "      <th>SIN(V7_day)</th>\n",
       "      <th>SIN(V23_month)</th>\n",
       "      <th>SIN(V23_day)</th>\n",
       "      <th>SIN(V8_month)</th>\n",
       "      <th>SIN(V8_day)</th>\n",
       "      <th>V6_year</th>\n",
       "      <th>V7_year</th>\n",
       "      <th>V23_year</th>\n",
       "      <th>V8_year</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>150000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>2976</td>\n",
       "      <td>44</td>\n",
       "      <td>58109</td>\n",
       "      <td>...</td>\n",
       "      <td>7.657137e-16</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.937752</td>\n",
       "      <td>2.012985e-01</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>2009</td>\n",
       "      <td>2011</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>89596.363811</td>\n",
       "      <td>19</td>\n",
       "      <td>2976</td>\n",
       "      <td>61</td>\n",
       "      <td>41777</td>\n",
       "      <td>...</td>\n",
       "      <td>7.657137e-16</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.937752</td>\n",
       "      <td>-1.224647e-16</td>\n",
       "      <td>0.101168</td>\n",
       "      <td>2008</td>\n",
       "      <td>2010</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>379231</td>\n",
       "      <td>37691.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>2976</td>\n",
       "      <td>44</td>\n",
       "      <td>39166</td>\n",
       "      <td>...</td>\n",
       "      <td>7.657137e-16</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.937752</td>\n",
       "      <td>6.652418e-01</td>\n",
       "      <td>-0.988468</td>\n",
       "      <td>2017</td>\n",
       "      <td>2019</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>540979</td>\n",
       "      <td>314511.583976</td>\n",
       "      <td>19</td>\n",
       "      <td>2932</td>\n",
       "      <td>44</td>\n",
       "      <td>25917</td>\n",
       "      <td>...</td>\n",
       "      <td>7.657137e-16</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.937752</td>\n",
       "      <td>6.652418e-01</td>\n",
       "      <td>0.651372</td>\n",
       "      <td>2009</td>\n",
       "      <td>2011</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>150000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>2976</td>\n",
       "      <td>104</td>\n",
       "      <td>47733</td>\n",
       "      <td>...</td>\n",
       "      <td>7.657137e-16</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.937752</td>\n",
       "      <td>2.012985e-01</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>2017</td>\n",
       "      <td>2019</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1  V2  V3  V4      V9            V10  V12   V13  V16    V19  ...  \\\n",
       "0   1   1  23   1  150000     300.000000   19  2976   44  58109  ...   \n",
       "1   0   1   2   1   10000   89596.363811   19  2976   61  41777  ...   \n",
       "2   4   2  23   1  379231   37691.000000   19  2976   44  39166  ...   \n",
       "3   4   2  23   1  540979  314511.583976   19  2932   44  25917  ...   \n",
       "4   1   1  23   1  150000  150000.000000   19  2976  104  47733  ...   \n",
       "\n",
       "    SIN(V7_day)  SIN(V23_month)  SIN(V23_day)  SIN(V8_month)  SIN(V8_day)  \\\n",
       "0  7.657137e-16        0.201299      0.937752   2.012985e-01     0.201299   \n",
       "1  7.657137e-16        0.201299      0.937752  -1.224647e-16     0.101168   \n",
       "2  7.657137e-16        0.201299      0.937752   6.652418e-01    -0.988468   \n",
       "3  7.657137e-16        0.201299      0.937752   6.652418e-01     0.651372   \n",
       "4  7.657137e-16        0.201299      0.937752   2.012985e-01     0.201299   \n",
       "\n",
       "   V6_year  V7_year  V23_year  V8_year  CLASS  \n",
       "0     2009     2011      2010     2010      1  \n",
       "1     2008     2010      2011     2011      1  \n",
       "2     2017     2019      2018     2018      1  \n",
       "3     2009     2011      2010     2010      1  \n",
       "4     2017     2019      2018     2018      1  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_fraud = data[data['CLASS'] == 0].sample(1000)\n",
    "fraud = data[data['CLASS'] == 1]\n",
    "\n",
    "df = non_fraud.append(fraud).sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['CLASS'], axis = 1).values\n",
    "Y = df[\"CLASS\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sihartist/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:795: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/home/sihartist/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:805: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be real number, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/formatters.py:339\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 339\u001b[0m     \u001b[39mreturn\u001b[39;00m printer(obj)\n\u001b[1;32m    340\u001b[0m \u001b[39m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    341\u001b[0m method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:151\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    149\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 151\u001b[0m fig\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mprint_figure(bytes_io, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    152\u001b[0m data \u001b[39m=\u001b[39m bytes_io\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    153\u001b[0m \u001b[39mif\u001b[39;00m fmt \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msvg\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/backend_bases.py:2319\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2316\u001b[0m     \u001b[39m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2317\u001b[0m     \u001b[39m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2318\u001b[0m     \u001b[39mwith\u001b[39;00m cbook\u001b[39m.\u001b[39m_setattr_cm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure, dpi\u001b[39m=\u001b[39mdpi):\n\u001b[0;32m-> 2319\u001b[0m         result \u001b[39m=\u001b[39m print_method(\n\u001b[1;32m   2320\u001b[0m             filename,\n\u001b[1;32m   2321\u001b[0m             facecolor\u001b[39m=\u001b[39;49mfacecolor,\n\u001b[1;32m   2322\u001b[0m             edgecolor\u001b[39m=\u001b[39;49medgecolor,\n\u001b[1;32m   2323\u001b[0m             orientation\u001b[39m=\u001b[39;49morientation,\n\u001b[1;32m   2324\u001b[0m             bbox_inches_restore\u001b[39m=\u001b[39;49m_bbox_inches_restore,\n\u001b[1;32m   2325\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2326\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   2327\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/backend_bases.py:1648\u001b[0m, in \u001b[0;36m_check_savefig_extra_args.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1640\u001b[0m     _api\u001b[39m.\u001b[39mwarn_deprecated(\n\u001b[1;32m   1641\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m3.3\u001b[39m\u001b[39m'\u001b[39m, name\u001b[39m=\u001b[39mname, removal\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m3.6\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1642\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%(name)s\u001b[39;00m\u001b[39m() got unexpected keyword argument \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1643\u001b[0m                 \u001b[39m+\u001b[39m arg \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m which is no longer supported as of \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1644\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m%(since)s\u001b[39;00m\u001b[39m and will become an error \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1645\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m%(removal)s\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1646\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(arg)\n\u001b[0;32m-> 1648\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/_api/deprecation.py:412\u001b[0m, in \u001b[0;36mdelete_parameter.<locals>.wrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m     deprecation_addendum \u001b[39m=\u001b[39m (\n\u001b[1;32m    403\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIf any parameter follows \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m!r}\u001b[39;00m\u001b[39m, they should be passed as \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    404\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mkeyword, not positionally.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    405\u001b[0m     warn_deprecated(\n\u001b[1;32m    406\u001b[0m         since,\n\u001b[1;32m    407\u001b[0m         name\u001b[39m=\u001b[39m\u001b[39mrepr\u001b[39m(name),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m                  \u001b[39melse\u001b[39;00m deprecation_addendum,\n\u001b[1;32m    411\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 412\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49minner_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minner_kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:540\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[39m@_check_savefig_extra_args\u001b[39m\n\u001b[1;32m    491\u001b[0m \u001b[39m@_api\u001b[39m\u001b[39m.\u001b[39mdelete_parameter(\u001b[39m\"\u001b[39m\u001b[39m3.5\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    492\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprint_png\u001b[39m(\u001b[39mself\u001b[39m, filename_or_obj, \u001b[39m*\u001b[39margs,\n\u001b[1;32m    493\u001b[0m               metadata\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, pil_kwargs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    494\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[39m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[39m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 540\u001b[0m     FigureCanvasAgg\u001b[39m.\u001b[39;49mdraw(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    541\u001b[0m     mpl\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mimsave(\n\u001b[1;32m    542\u001b[0m         filename_or_obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_rgba(), \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpng\u001b[39m\u001b[39m\"\u001b[39m, origin\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mupper\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    543\u001b[0m         dpi\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39mdpi, metadata\u001b[39m=\u001b[39mmetadata, pil_kwargs\u001b[39m=\u001b[39mpil_kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:436\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[39mwith\u001b[39;00m RendererAgg\u001b[39m.\u001b[39mlock, \\\n\u001b[1;32m    434\u001b[0m      (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoolbar\u001b[39m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoolbar\n\u001b[1;32m    435\u001b[0m       \u001b[39melse\u001b[39;00m nullcontext()):\n\u001b[0;32m--> 436\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdraw(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrenderer)\n\u001b[1;32m    437\u001b[0m     \u001b[39m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     \u001b[39m# don't forget to call the superclass.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mdraw()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/artist.py:73\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39m@wraps\u001b[39m(draw)\n\u001b[1;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_wrapper\u001b[39m(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 73\u001b[0m     result \u001b[39m=\u001b[39m draw(artist, renderer, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m renderer\u001b[39m.\u001b[39m_rasterizing:\n\u001b[1;32m     75\u001b[0m         renderer\u001b[39m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     51\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/figure.py:2810\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2807\u001b[0m         \u001b[39m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   2809\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 2810\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   2811\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   2813\u001b[0m \u001b[39mfor\u001b[39;00m sfig \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubfigs:\n\u001b[1;32m   2814\u001b[0m     sfig\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    131\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 132\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    133\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     51\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/axes/_base.py:3082\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3079\u001b[0m         a\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[1;32m   3080\u001b[0m     renderer\u001b[39m.\u001b[39mstop_rasterizing()\n\u001b[0;32m-> 3082\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   3083\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   3085\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39maxes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   3086\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    131\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 132\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    133\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     51\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/collections.py:991\u001b[0m, in \u001b[0;36m_CollectionWithSizes.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[39m@artist\u001b[39m\u001b[39m.\u001b[39mallow_rasterization\n\u001b[1;32m    989\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw\u001b[39m(\u001b[39mself\u001b[39m, renderer):\n\u001b[1;32m    990\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_sizes(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sizes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39mdpi)\n\u001b[0;32m--> 991\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdraw(renderer)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     51\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/collections.py:422\u001b[0m, in \u001b[0;36mCollection.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    420\u001b[0m     gc\u001b[39m.\u001b[39mset_antialiased(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_antialiaseds[\u001b[39m0\u001b[39m])\n\u001b[1;32m    421\u001b[0m     gc\u001b[39m.\u001b[39mset_url(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_urls[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> 422\u001b[0m     renderer\u001b[39m.\u001b[39;49mdraw_markers(\n\u001b[1;32m    423\u001b[0m         gc, paths[\u001b[39m0\u001b[39;49m], combined_transform\u001b[39m.\u001b[39;49mfrozen(),\n\u001b[1;32m    424\u001b[0m         mpath\u001b[39m.\u001b[39;49mPath(offsets), transOffset, \u001b[39mtuple\u001b[39;49m(facecolors[\u001b[39m0\u001b[39;49m]))\n\u001b[1;32m    425\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m     renderer\u001b[39m.\u001b[39mdraw_path_collection(\n\u001b[1;32m    427\u001b[0m         gc, transform\u001b[39m.\u001b[39mfrozen(), paths,\n\u001b[1;32m    428\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_transforms(), offsets, transOffset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_antialiaseds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_urls,\n\u001b[1;32m    432\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offset_position)\n",
      "\u001b[0;31mTypeError\u001b[0m: must be real number, not str"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tsne_plot(x1, y1, name=\"graph.png\"):\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    X_t = tsne.fit_transform(x1)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(X_t[np.where(y1 == 0), 0], X_t[np.where(y1 == 0), 1], marker='o', color='g', linewidth='1', alpha=0.8, label='Non Fraud')\n",
    "    plt.scatter(X_t[np.where(y1 == 1), 0], X_t[np.where(y1 == 1), 1], marker='o', color='r', linewidth='1', alpha=0.8, label='Fraud')\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    #plt.savefig(name)\n",
    "    plt.show()\n",
    "    \n",
    "tsne_plot(X, Y, \"original.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_x = np.append(norm_hid_rep, fraud_hid_rep, axis = 0)\n",
    "y_n = np.zeros(norm_hid_rep.shape[0])\n",
    "y_f = np.ones(fraud_hid_rep.shape[0])\n",
    "rep_y = np.append(y_n, y_f)\n",
    "tsne_plot(rep_x, rep_y, \"latent_representation.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(rep_x, rep_y, test_size=0.25)\n",
    "clf = LogisticRegression().fit(train_x, train_y)\n",
    "pred_y = clf.predict(val_x)\n",
    "\n",
    "print (\"\")\n",
    "print (\"confusion_matrixt: \")\n",
    "print (confusion_matrix(val_y, pred_y))\n",
    "\n",
    "print (\"\")\n",
    "print (\"Accuracy Score: \", accuracy_score(val_y, pred_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cfdbd8c9048ab92b077343f235d6ccc68a76f62a5f525420b39b88fd49e8f01a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
