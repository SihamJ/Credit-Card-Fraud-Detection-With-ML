{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(row):\n",
    "\n",
    "    root=\"C:/Users/KABYADE/Desktop/Fraud_ML/\"\n",
    "    encoder_path = \"fraud-detection/preprocessing/output/dict_all.obj\"\n",
    "    scalerfile = 'fraud-detection/preprocessing/output/scaler.sav'\n",
    "\n",
    "    # loading scaler\n",
    "    min_max_scaler = pickle.load(open(root + scalerfile, 'rb'))\n",
    "\n",
    "    # loading encoder dictionary\n",
    "    file = open(root + encoder_path,'rb')\n",
    "    dict_encoder = pickle.load(file)\n",
    "    file.close()\n",
    "\n",
    "    # treating nan values\n",
    "    row.drop(['V11','V14','V20','V5','V17','V18','V15','CLASS'], inplace=True)\n",
    "\n",
    "    # updating types\n",
    "    row['V10'] = float(row['V10'])\n",
    "    row['V9'] = float(row['V9'])\n",
    "    row['V24'] = float(row['V24'])\n",
    "\n",
    "    row['V23'] = pd.to_datetime(row['V23'],format=\"%d/%m/%Y\")\n",
    "    row['V8'] = pd.to_datetime(row['V8'],format=\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "    row['V6'] = pd.to_datetime(row['V6'],format=\"%d/%m/%Y\")\n",
    "    row['V7'] = pd.to_datetime(row['V7'],format=\"%d/%m/%Y\")\n",
    "\n",
    "    # preprocess dates\n",
    "    date_cols = ['V6','V7','V23','V8']\n",
    "    years = {}\n",
    "    date_rows = {}\n",
    "\n",
    "    for l in date_cols:\n",
    "        date_rows[l+'_month'] = row[l].month\n",
    "        date_rows[l+'_day'] = row[l].day\n",
    "        years[l+'_year'] = row[l].year\n",
    "        row.pop(l)\n",
    "\n",
    "    cos_cols = list(date_rows.keys())\n",
    "    sin_cols = list(date_rows.keys())\n",
    "\n",
    "\n",
    "    for i in range(len(cos_cols)):\n",
    "        cos_cols[i] = 'COS(' + cos_cols[i] + ')'\n",
    "        sin_cols[i] = 'SIN(' + sin_cols[i] + ')'\n",
    "\n",
    "    # Normalize date cols\n",
    "    date_row_scaled = min_max_scaler.transform(np.array(list(date_rows.values())).reshape(-1,8))\n",
    "    date_row_scaled = date_row_scaled.reshape(8)\n",
    "\n",
    "    cos_row_scaled = dict(zip(cos_cols, date_row_scaled))\n",
    "    sin_row_scaled = dict(zip(sin_cols, date_row_scaled))\n",
    "\n",
    "    date_row_cos = pd.Series(cos_row_scaled)\n",
    "    date_row_sin = pd.Series(sin_row_scaled)\n",
    "    date_row_cos = date_row_cos.apply(lambda x: math.cos(x))\n",
    "    date_row_sin = date_row_sin.apply(lambda x: math.sin(x))\n",
    "\n",
    "    year_row = pd.Series(years)\n",
    "\n",
    "    new_row = pd.concat([row, date_row_cos, date_row_sin, year_row], axis=0)\n",
    "\n",
    "    # encoding\n",
    "    for col in dict_encoder.keys():\n",
    "        if(new_row[col] in dict_encoder[col].keys()):\n",
    "            new_row.replace(dict_encoder[col], inplace=True)\n",
    "        else:\n",
    "            new_row[col] = -1\n",
    "\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/KABYADE/Desktop/Fraud_ML/dataset/final.xlsx'\n",
    "df = pd.read_excel(path, dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt=\"C:/Users/KABYADE/Desktop/Fraud_ML/\"\n",
    "encoder_path = rt+\"fraud-detection/preprocessing/output/dict_all.obj\"\n",
    "scalerfile = rt+'fraud-detection/preprocessing/output/scaler.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.iloc[1]\n",
    "row['V10'] = 643212\n",
    "row['V9'] = 239806.0\n",
    "row['V24'] = 777541\n",
    "\n",
    "file = open( rt + \"fraud-detection/preprocessing/output/row.obj\",\"wb\")\n",
    "pickle.dump(row, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = pickle.load(open(rt + \"fraud-detection/preprocessing/output/row.obj\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = preprocess(row)\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file = open( rt + \"fraud-detection/preprocessing/output/new_row.obj\",\"wb\")\n",
    "pickle.dump(new_row, new_file)\n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypmml import Model\n",
    "\n",
    "filename = \"fraud-detection/models/svm.pmml\"\n",
    "SVM = Model.load(root + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = SVM.predict(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_isFraud    1.0\n",
       "probability          1.0\n",
       "probability_0        0.0\n",
       "probability_1        1.0\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9dce4b41c3dab15c9b172253d5926c6876aa54e726307ae26a963b8959ab689a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
